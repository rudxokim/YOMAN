# YOMAN Causal Consistency Application Guide

> **ëª©ì **: YOMANì˜ ë²„í‚· ì‹œìŠ¤í…œê³¼ GAN ê²€ì¦ì— causal consistencyë¥¼ ì‹¤ì œ ì ìš©í•˜ëŠ” ìƒì„¸ ê°€ì´ë“œ

---

## 1. YOMAN ì•„í‚¤í…ì²˜ ë¦¬ë·°

### 1.1 í˜„ì¬ ì‹œìŠ¤í…œ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Interface Layer (Slack)                                     â”‚
â”‚  - ì‚¬ìš©ì ì…ë ¥ (í…ìŠ¤íŠ¸/ìŒì„±)                                  â”‚
â”‚  - ë²„í‚·ë³„ ì±„ë„ (#yoman-ideas, #yoman-research, ...)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bucket System (ë¬¼ìˆ˜ì œë¹„)                                    â”‚
â”‚  IDEA â†’ RESEARCH â†’ TODO â†’ PR                                â”‚
â”‚       â†˜ STUDY                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Engine Layer (UnitService)                                  â”‚
â”‚  Tier 3 (Opus) â†’ Tier 2 (Sonnet) â†’ Tier 1 (Flash/GLM)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Storage (Supabase)                                          â”‚
â”‚  + Memory MCP (ì§€ì‹ ê·¸ë˜í”„)                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 Causal Dependency í˜„í™©

**ëª…í™•í•œ Causal Chain**:
```
IDEA_1 (ë…ë¦½)
  â†“ (happens-before)
RESEARCH_1 (depends_on: IDEA_1)
  â†“ (happens-before)
TODO_1 (depends_on: RESEARCH_1, prerequisites: [])
  â†“ (happens-before)
PR_1 (depends_on: TODO_1, generated_by: CODINGBOT)
  â†“ (happens-before)
REVIEWER_result (depends_on: PR_1, TODO_1.acceptance_criteria)
```

**Concurrent Operations** (ì¸ê³¼ ê´€ê³„ ì—†ìŒ):
```
IDEA_1, IDEA_2, IDEA_3 (ë™ì‹œ ìƒì„± ê°€ëŠ¥)
TODO_5, TODO_6 (ë‹¤ë¥¸ RESEARCHì—ì„œ íŒŒìƒ, ë³‘ë ¬ ì²˜ë¦¬)
Unit_A1, Unit_A2, Unit_A3 (ì–‘ì ê²€ì¦, 3ê°œ ëª¨ë¸ ë™ì‹œ ìƒì„±)
```

---

## 2. Causal Consistency ì ìš© ì „ëµ

### 2.1 Phase 1: Vector Clock ê¸°ë³¸ ì ìš©

**ëª©í‘œ**: ëª¨ë“  Operationì— vector clock ì¶”ê°€í•˜ì—¬ ì¸ê³¼ê´€ê³„ ì¶”ì 

#### 2.1.1 Supabase ìŠ¤í‚¤ë§ˆ í™•ì¥

```sql
-- ê¸°ì¡´ í…Œì´ë¸” ìˆ˜ì •
ALTER TABLE ideas ADD COLUMN vector_clock JSONB DEFAULT '{}'::jsonb;
ALTER TABLE research ADD COLUMN vector_clock JSONB DEFAULT '{}'::jsonb;
ALTER TABLE todos ADD COLUMN vector_clock JSONB DEFAULT '{}'::jsonb;
ALTER TABLE prs ADD COLUMN vector_clock JSONB DEFAULT '{}'::jsonb;

-- Dependencies ì»¬ëŸ¼ ì¶”ê°€
ALTER TABLE ideas ADD COLUMN dependencies JSONB DEFAULT '[]'::jsonb;
ALTER TABLE research ADD COLUMN dependencies JSONB DEFAULT '[]'::jsonb;
ALTER TABLE todos ADD COLUMN dependencies JSONB DEFAULT '[]'::jsonb;
ALTER TABLE prs ADD COLUMN dependencies JSONB DEFAULT '[]'::jsonb;

-- ì¸ë±ìŠ¤ ì¶”ê°€
CREATE INDEX idx_ideas_vc ON ideas USING GIN (vector_clock);
CREATE INDEX idx_research_vc ON research USING GIN (vector_clock);
CREATE INDEX idx_todos_vc ON todos USING GIN (vector_clock);
CREATE INDEX idx_prs_vc ON prs USING GIN (vector_clock);
```

#### 2.1.2 Python Service ìˆ˜ì •

```python
# yoman/services/bucket_service.py

from yoman.causal import VectorClock, Operation, BucketType
from supabase import Client

class BucketService:
    def __init__(self, supabase: Client, node_id: str = "yoman_server"):
        self.db = supabase
        self.node_id = node_id
        self.my_clock = VectorClock()

    async def create_idea(
        self,
        project_id: str,
        content: dict,
        user_id: str
    ) -> str:
        """IDEA ìƒì„± (vector clock ì ìš©)"""

        # Vector clock ì¦ê°€
        self.my_clock.increment(self.node_id)

        # IDEA ë°ì´í„°
        idea_data = {
            "project_id": project_id,
            "content": content,
            "vector_clock": self.my_clock.to_json(),
            "dependencies": [],  # IDEAëŠ” ì˜ì¡´ì„± ì—†ìŒ
            "created_by": user_id
        }

        # DB ì‚½ì…
        result = self.db.table("ideas").insert(idea_data).execute()
        idea_id = result.data[0]["id"]

        # Slack ì•Œë¦¼
        await self.notify_slack(
            channel="yoman-ideas",
            message=f"ğŸ’¡ New IDEA: {content.get('title', 'Untitled')}\nID: {idea_id}"
        )

        return idea_id

    async def create_research(
        self,
        idea_id: str,
        content: dict,
        user_id: str
    ) -> str:
        """RESEARCH ìƒì„± (IDEAì— ì˜ì¡´)"""

        # 1. IDEA ì¡°íšŒ
        idea_result = self.db.table("ideas").select("*").eq("id", idea_id).execute()
        if not idea_result.data:
            raise ValueError(f"IDEA {idea_id} not found")

        idea = idea_result.data[0]
        idea_clock = VectorClock.from_json(idea["vector_clock"])

        # 2. Vector clock ë³‘í•© ë° ì¦ê°€
        self.my_clock.merge(idea_clock)
        self.my_clock.increment(self.node_id)

        # 3. RESEARCH ë°ì´í„°
        research_data = {
            "project_id": idea["project_id"],
            "idea_id": idea_id,
            "content": content,
            "vector_clock": self.my_clock.to_json(),
            "dependencies": [
                {
                    "id": idea_id,
                    "bucket": "IDEA",
                    "version": idea.get("version", 1)
                }
            ],
            "created_by": user_id
        }

        # 4. DB ì‚½ì…
        result = self.db.table("research").insert(research_data).execute()
        research_id = result.data[0]["id"]

        # 5. Slack ì•Œë¦¼
        await self.notify_slack(
            channel="yoman-research",
            message=f"ğŸ“Š New RESEARCH: {content.get('title', 'Untitled')}\n"
                    f"ID: {research_id}\n"
                    f"Based on IDEA: {idea_id}"
        )

        return research_id

    async def create_todo(
        self,
        research_id: str,
        content: dict,
        prerequisites: list[str],
        user_id: str
    ) -> str:
        """TODO ìƒì„± (RESEARCH + Prerequisitesì— ì˜ì¡´)"""

        # 1. RESEARCH ì¡°íšŒ
        research_result = self.db.table("research").select("*").eq("id", research_id).execute()
        if not research_result.data:
            raise ValueError(f"RESEARCH {research_id} not found")

        research = research_result.data[0]
        research_clock = VectorClock.from_json(research["vector_clock"])

        # 2. Prerequisites ì¡°íšŒ ë° vector clock ë³‘í•©
        deps = [
            {
                "id": research_id,
                "bucket": "RESEARCH",
                "version": research.get("version", 1)
            }
        ]

        combined_clock = VectorClock(clocks=research_clock.clocks.copy())

        for prereq_id in prerequisites:
            prereq_result = self.db.table("todos").select("*").eq("id", prereq_id).execute()
            if prereq_result.data:
                prereq = prereq_result.data[0]
                prereq_clock = VectorClock.from_json(prereq["vector_clock"])
                combined_clock.merge(prereq_clock)

                deps.append({
                    "id": prereq_id,
                    "bucket": "TODO",
                    "version": prereq.get("version", 1)
                })

        # 3. Vector clock ì¦ê°€
        combined_clock.increment(self.node_id)

        # 4. TODO ë°ì´í„°
        todo_data = {
            "project_id": research["project_id"],
            "research_id": research_id,
            "content": content,
            "prerequisites": prerequisites,
            "acceptance_criteria": content.get("acceptance_criteria", []),
            "vector_clock": combined_clock.to_json(),
            "dependencies": deps,
            "created_by": user_id,
            "status": "pending"
        }

        # 5. DB ì‚½ì…
        result = self.db.table("todos").insert(todo_data).execute()
        todo_id = result.data[0]["id"]

        # 6. Prerequisites ì²´í¬ ë° Slack ì•Œë¦¼
        all_satisfied = await self.check_prerequisites(prerequisites)

        status_emoji = "âœ…" if all_satisfied else "â³"
        await self.notify_slack(
            channel="yoman-todos",
            message=f"{status_emoji} New TODO: {content.get('title', 'Untitled')}\n"
                    f"ID: {todo_id}\n"
                    f"Prerequisites: {len(prerequisites)} (satisfied: {all_satisfied})"
        )

        return todo_id

    async def check_prerequisites(self, prereq_ids: list[str]) -> bool:
        """Prerequisitesê°€ ëª¨ë‘ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸"""
        if not prereq_ids:
            return True

        for prereq_id in prereq_ids:
            result = self.db.table("todos").select("status").eq("id", prereq_id).execute()
            if not result.data or result.data[0]["status"] != "completed":
                return False

        return True
```

### 2.2 Phase 2: GAN ê²€ì¦ì— Causal Consistency ì ìš©

**ë¬¸ì œ**: CODINGBOT(Generator)ê³¼ REVIEWER(Discriminator)ì˜ ì¸ê³¼ê´€ê³„ ëª…í™•í™”

#### 2.2.1 GAN íŒ¨í„´ ë¶„ì„

```
TODO â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”œâ”€â”€â”€â–º CODINGBOT â”€â”€â”€â–º PR â”€â”€â”€â”
             â”‚                          â”œâ”€â”€â”€â–º REVIEWER â”€â”€â”€â–º Result
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                (Acceptance Criteria)
```

**Causal Dependencies**:
1. `PR` depends on `TODO` (ì…ë ¥ ìŠ¤í™)
2. `REVIEWER` depends on `PR` (ìƒì„±ëœ ì½”ë“œ)
3. `REVIEWER` depends on `TODO` (ê²€ì¦ ê¸°ì¤€)

**Vector Clock íë¦„**:
```python
TODO: {server: 3}
  â†“
PR: {server: 4}  # TODO clock ë³‘í•© í›„ ì¦ê°€
  â†“
REVIEWER: {server: 5}  # PR clock ë³‘í•© í›„ ì¦ê°€
```

#### 2.2.2 CODINGBOT Service

```python
# yoman/agents/codingbot.py

class CodingBot:
    def __init__(self, model: str = "grok-code-fast-1"):
        self.model = model
        self.node_id = f"codingbot_{model}"
        self.clock = VectorClock()

    async def generate_code(
        self,
        todo_id: str,
        db: Client
    ) -> str:
        """TODOë¡œë¶€í„° ì½”ë“œ ìƒì„±"""

        # 1. TODO ì¡°íšŒ
        todo_result = db.table("todos").select("*").eq("id", todo_id).execute()
        if not todo_result.data:
            raise ValueError(f"TODO {todo_id} not found")

        todo = todo_result.data[0]
        todo_clock = VectorClock.from_json(todo["vector_clock"])

        # 2. Vector clock ë³‘í•©
        self.clock.merge(todo_clock)
        self.clock.increment(self.node_id)

        # 3. ì½”ë“œ ìƒì„± (ì‹¤ì œ LLM í˜¸ì¶œ)
        code = await self._call_llm(
            model=self.model,
            prompt=self._build_prompt(todo)
        )

        # 4. PR ìƒì„±
        pr_data = {
            "todo_id": todo_id,
            "project_id": todo["project_id"],
            "code": code,
            "vector_clock": self.clock.to_json(),
            "dependencies": [
                {
                    "id": todo_id,
                    "bucket": "TODO",
                    "version": todo.get("version", 1)
                }
            ],
            "generated_by": self.node_id,
            "status": "pending_review"
        }

        result = db.table("prs").insert(pr_data).execute()
        pr_id = result.data[0]["id"]

        return pr_id

    async def _call_llm(self, model: str, prompt: str) -> str:
        """ì‹¤ì œ LLM API í˜¸ì¶œ"""
        # Grok API í˜¸ì¶œ ë¡œì§
        pass

    def _build_prompt(self, todo: dict) -> str:
        """TODOì—ì„œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return f"""
        Generate code for the following task:

        Title: {todo['content'].get('title')}
        Description: {todo['content'].get('description')}

        Prerequisites:
        {chr(10).join(f"- {p}" for p in todo.get('prerequisites', []))}

        Acceptance Criteria:
        {chr(10).join(f"- {c}" for c in todo.get('acceptance_criteria', []))}

        Generate clean, tested code that satisfies all criteria.
        """
```

#### 2.2.3 REVIEWER Service

```python
# yoman/agents/reviewer.py

class Reviewer:
    def __init__(self, model: str = "claude-opus-4.5"):
        self.model = model
        self.node_id = "reviewer"
        self.clock = VectorClock()

    async def review_pr(
        self,
        pr_id: str,
        db: Client
    ) -> dict:
        """PR ë¦¬ë·° (Pass/Fail íŒì •)"""

        # 1. PR ì¡°íšŒ
        pr_result = db.table("prs").select("*").eq("id", pr_id).execute()
        if not pr_result.data:
            raise ValueError(f"PR {pr_id} not found")

        pr = pr_result.data[0]
        pr_clock = VectorClock.from_json(pr["vector_clock"])

        # 2. TODO ì¡°íšŒ (Acceptance Criteria)
        todo_id = pr["todo_id"]
        todo_result = db.table("todos").select("*").eq("id", todo_id).execute()
        todo = todo_result.data[0]
        todo_clock = VectorClock.from_json(todo["vector_clock"])

        # 3. Vector clock ë³‘í•© (PRê³¼ TODO ëª¨ë‘ ì˜ì¡´)
        self.clock.merge(pr_clock)
        self.clock.merge(todo_clock)
        self.clock.increment(self.node_id)

        # 4. ë¦¬ë·° ìˆ˜í–‰
        result = await self._perform_review(pr, todo)

        # 5. ë¦¬ë·° ê²°ê³¼ ì €ì¥
        review_data = {
            "pr_id": pr_id,
            "todo_id": todo_id,
            "result": result["verdict"],  # "PASS" or "FAIL"
            "details": result["details"],
            "vector_clock": self.clock.to_json(),
            "dependencies": [
                {"id": pr_id, "bucket": "PR", "version": pr.get("version", 1)},
                {"id": todo_id, "bucket": "TODO", "version": todo.get("version", 1)}
            ],
            "reviewed_by": self.node_id
        }

        db.table("reviews").insert(review_data).execute()

        # 6. PR ìƒíƒœ ì—…ë°ì´íŠ¸
        new_status = "approved" if result["verdict"] == "PASS" else "changes_requested"
        db.table("prs").update({"status": new_status}).eq("id", pr_id).execute()

        return result

    async def _perform_review(self, pr: dict, todo: dict) -> dict:
        """ì‹¤ì œ ë¦¬ë·° ë¡œì§"""

        acceptance_criteria = todo.get("acceptance_criteria", [])
        code = pr["code"]

        # 1. í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_results = await self._run_tests(code)

        # 2. Acceptance Criteria ì²´í¬
        criteria_checks = []
        for criterion in acceptance_criteria:
            passed = await self._check_criterion(code, criterion)
            criteria_checks.append({
                "criterion": criterion,
                "passed": passed
            })

        # 3. Pass/Fail íŒì • (ëª¨ë“  ê¸°ì¤€ ì¶©ì¡±í•´ì•¼ PASS)
        all_passed = (
            test_results["pass_rate"] == 1.0 and
            all(c["passed"] for c in criteria_checks)
        )

        verdict = "PASS" if all_passed else "FAIL"

        return {
            "verdict": verdict,
            "details": {
                "tests": test_results,
                "criteria": criteria_checks
            }
        }

    async def _run_tests(self, code: str) -> dict:
        """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰ ë¡œì§
        pass

    async def _check_criterion(self, code: str, criterion: str) -> bool:
        """Acceptance criterion ì²´í¬"""
        # LLMì„ ì‚¬ìš©í•˜ì—¬ criterion ì¶©ì¡± ì—¬ë¶€ íŒë‹¨
        pass
```

### 2.3 Phase 3: Concurrent Unit Generation (ì–‘ì ê²€ì¦)

**ëª©í‘œ**: ì—¬ëŸ¬ AI ëª¨ë¸ì´ ë™ì‹œì— ìœ ë‹› ìƒì„± â†’ Concurrent operations

#### 2.3.1 ë³‘ë ¬ ìœ ë‹› ìƒì„±

```python
# yoman/agents/quantum_verification.py

import asyncio
from typing import List

class QuantumVerifier:
    """
    ì—¬ëŸ¬ ëª¨ë¸ë¡œ ë™ì‹œì— ìœ ë‹› ìƒì„± í›„ í…ŒìŠ¤íŠ¸ í†µê³¼í•œ ìµœì  ì„ íƒ

    Causal Consistency:
    - ê° ëª¨ë¸ì˜ outputì€ CONCURRENT (ì¸ê³¼ ê´€ê³„ ì—†ìŒ)
    - ìµœì¢… ì„ íƒì€ ëª¨ë“  outputì— ì˜ì¡´
    """

    def __init__(self):
        self.models = ["grok-code-fast-1", "gemini-2.0-flash", "deepseek-coder"]
        self.node_id = "quantum_verifier"
        self.clock = VectorClock()

    async def generate_unit(
        self,
        spec: dict,
        parent_clock: VectorClock,
        db: Client
    ) -> str:
        """
        ì—¬ëŸ¬ ëª¨ë¸ë¡œ ìœ ë‹› ìƒì„± (ë³‘ë ¬)

        Args:
            spec: ìœ ë‹› ìŠ¤í™
            parent_clock: ë¶€ëª¨ operationì˜ vector clock
            db: Supabase client

        Returns:
            ìµœì  ìœ ë‹› ID
        """

        # 1. ê° ëª¨ë¸ë¡œ ë³‘ë ¬ ìƒì„±
        tasks = [
            self._generate_with_model(model, spec, parent_clock)
            for model in self.models
        ]

        units = await asyncio.gather(*tasks)

        # 2. ê° ìœ ë‹›ì˜ vector clockì€ CONCURRENT
        for i in range(len(units)):
            for j in range(i + 1, len(units)):
                relation = units[i]["clock"].compare(units[j]["clock"])
                assert relation == 'CONCURRENT', "Units should be concurrent"

        # 3. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ë³‘ë ¬)
        test_tasks = [
            self._test_unit(unit["code"])
            for unit in units
        ]

        test_results = await asyncio.gather(*test_tasks)

        # 4. í†µê³¼í•œ ìœ ë‹› ì¤‘ ìµœì  ì„ íƒ
        passed_units = [
            (unit, result)
            for unit, result in zip(units, test_results)
            if result["passed"]
        ]

        if not passed_units:
            raise Exception("No units passed tests")

        # ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ (ì»¤ë²„ë¦¬ì§€, ì„±ëŠ¥ ë“±)
        best_unit, best_result = max(
            passed_units,
            key=lambda x: x[1]["score"]
        )

        # 5. ìµœì¢… ì„ íƒí•œ ìœ ë‹› ì €ì¥
        # Vector clockì€ ëª¨ë“  candidate units ë³‘í•©
        final_clock = VectorClock()
        for unit in units:
            final_clock.merge(unit["clock"])
        final_clock.increment(self.node_id)

        unit_data = {
            "spec": spec,
            "code": best_unit["code"],
            "model": best_unit["model"],
            "vector_clock": final_clock.to_json(),
            "dependencies": [
                # ëª¨ë“  candidate unitsì— ì˜ì¡´ (quantum superposition)
                {"id": unit["id"], "bucket": "UNIT_CANDIDATE"}
                for unit in units
            ],
            "test_result": best_result
        }

        result = db.table("units").insert(unit_data).execute()
        unit_id = result.data[0]["id"]

        return unit_id

    async def _generate_with_model(
        self,
        model: str,
        spec: dict,
        parent_clock: VectorClock
    ) -> dict:
        """ë‹¨ì¼ ëª¨ë¸ë¡œ ìœ ë‹› ìƒì„±"""

        # ê° ëª¨ë¸ë³„ ë…ë¦½ì ì¸ clock
        model_clock = VectorClock()
        model_clock.merge(parent_clock)
        model_clock.increment(f"model_{model}")

        # ì½”ë“œ ìƒì„±
        code = await self._call_model(model, spec)

        return {
            "id": str(uuid4()),
            "model": model,
            "code": code,
            "clock": model_clock
        }

    async def _test_unit(self, code: str) -> dict:
        """ìœ ë‹› í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        # ì‹¤ì œ í…ŒìŠ¤íŠ¸ ë¡œì§
        pass

    async def _call_model(self, model: str, spec: dict) -> str:
        """LLM API í˜¸ì¶œ"""
        # ì‹¤ì œ API í˜¸ì¶œ
        pass
```

#### 2.3.2 Visualization (Slack)

```python
# yoman/slack/visualizer.py

class CausalGraphVisualizer:
    """Slackì— causal graph ì‹œê°í™”"""

    @staticmethod
    def render_dependency_graph(op_id: str, db: Client) -> str:
        """
        Operationì˜ ì˜ì¡´ì„± ê·¸ë˜í”„ë¥¼ Mermaid diagramìœ¼ë¡œ ë Œë”ë§

        Returns:
            Mermaid syntax string
        """

        # ì˜ì¡´ì„± ê·¸ë˜í”„ ì¡°íšŒ
        graph = db.rpc("get_dependency_graph", {"op_id": op_id}).execute()

        # Mermaid ìƒì„±
        lines = ["```mermaid", "graph TD"]

        for node_id, deps in graph.data.items():
            node_label = f"{node_id[:8]}"  # ì§§ê²Œ í‘œì‹œ

            for dep_id in deps:
                dep_label = f"{dep_id[:8]}"
                lines.append(f"    {dep_label} --> {node_label}")

        lines.append("```")

        return "\n".join(lines)

    @staticmethod
    async def notify_concurrent_operations(
        ops: list[str],
        slack_client: any
    ) -> None:
        """
        Concurrent operations ì•Œë¦¼

        ì—¬ëŸ¬ operationì´ ë™ì‹œì— ì‹¤í–‰ ì¤‘ì„ì„ ì‹œê°í™”
        """

        message = "ğŸ”€ *Concurrent Operations Detected*\n\n"
        message += "ë‹¤ìŒ operationsëŠ” ì¸ê³¼ ê´€ê³„ê°€ ì—†ìœ¼ë¯€ë¡œ ë³‘ë ¬ ì²˜ë¦¬ë©ë‹ˆë‹¤:\n\n"

        for op_id in ops:
            message += f"â€¢ `{op_id}`\n"

        await slack_client.chat_postMessage(
            channel="yoman-alerts",
            text=message
        )
```

---

## 3. CALM Theorem í™œìš©

### 3.1 Monotonic Operations ì‹ë³„

**YOMANì˜ Monotonic Operations** (coordination-free):

```python
# yoman/calm/monotonic_ops.py

class MonotonicOperations:
    """
    YOMANì—ì„œ coordination ì—†ì´ ì‹¤í–‰ ê°€ëŠ¥í•œ operations

    CALM theorem: Monotonic operationsëŠ” ìµœì¢… ì¼ê´€ì„± ë³´ì¥
    """

    @staticmethod
    def is_monotonic(op_type: str, bucket: str) -> bool:
        """Operationì´ monotonicì¸ì§€ íŒë‹¨"""

        # Monotonic (coordination-free)
        monotonic_ops = {
            # ì¶”ê°€ operations
            ("create", "IDEA"),      # IDEA ì¶”ê°€ (ë…ë¦½ì )
            ("create", "STUDY"),     # STUDY ì¶”ê°€ (RESEARCHì—ì„œ ë¶„ê¸°)
            ("append", "LOG"),       # ë¡œê·¸ ì¶”ê°€
            ("increment", "COUNTER"), # ì¹´ìš´í„° ì¦ê°€

            # ì½ê¸° operations (side-effect ì—†ìŒ)
            ("read", "*"),
        }

        # Non-monotonic (coordination í•„ìš”)
        non_monotonic_ops = {
            # ì‚­ì œ/ê°ì†Œ operations
            ("delete", "TODO"),
            ("cancel", "PR"),
            ("decrement", "COUNTER"),

            # ì§‘ê³„ operations
            ("aggregate", "*"),
            ("average", "*"),
        }

        key = (op_type, bucket)

        if key in monotonic_ops:
            return True

        if key in non_monotonic_ops:
            return False

        # Wildcard ì²´í¬
        for op, bkt in monotonic_ops:
            if op == op_type and bkt == "*":
                return True

        # ê¸°ë³¸ê°’: non-monotonic (ì•ˆì „í•˜ê²Œ)
        return False
```

### 3.2 Coordination-Free Executor

```python
# yoman/executors/calm_executor.py

class CALMExecutor:
    """
    CALM theorem ê¸°ë°˜ ì‹¤í–‰ ì—”ì§„

    Monotonic ops â†’ ë³‘ë ¬ ì‹¤í–‰ (coordination-free)
    Non-monotonic ops â†’ ìˆœì°¨ ì‹¤í–‰ (locking í•„ìš”)
    """

    def __init__(self, db: Client):
        self.db = db
        self.lock = asyncio.Lock()

    async def execute_batch(
        self,
        operations: list[dict]
    ) -> list[any]:
        """
        Operation ë°°ì¹˜ ì‹¤í–‰

        Args:
            operations: [{"type": "create", "bucket": "IDEA", "data": {...}}, ...]

        Returns:
            ê° operationì˜ ê²°ê³¼
        """

        # 1. Monotonic/Non-monotonic ë¶„ë¥˜
        monotonic = []
        non_monotonic = []

        for op in operations:
            if MonotonicOperations.is_monotonic(op["type"], op["bucket"]):
                monotonic.append(op)
            else:
                non_monotonic.append(op)

        # 2. Monotonic operations ë³‘ë ¬ ì‹¤í–‰
        monotonic_results = await asyncio.gather(*[
            self._execute_single(op)
            for op in monotonic
        ])

        # 3. Non-monotonic operations ìˆœì°¨ ì‹¤í–‰ (lock)
        non_monotonic_results = []
        for op in non_monotonic:
            async with self.lock:
                result = await self._execute_single(op)
                non_monotonic_results.append(result)

        return monotonic_results + non_monotonic_results

    async def _execute_single(self, op: dict) -> any:
        """ë‹¨ì¼ operation ì‹¤í–‰"""
        op_type = op["type"]
        bucket = op["bucket"]
        data = op["data"]

        if op_type == "create" and bucket == "IDEA":
            return await self._create_idea(data)
        elif op_type == "create" and bucket == "RESEARCH":
            return await self._create_research(data)
        # ... ë‹¤ë¥¸ operations
        else:
            raise ValueError(f"Unknown operation: {op_type} {bucket}")

    async def _create_idea(self, data: dict) -> str:
        """IDEA ìƒì„± (monotonic)"""
        # BucketService í˜¸ì¶œ
        pass

    async def _create_research(self, data: dict) -> str:
        """RESEARCH ìƒì„± (monotonic if IDEA exists)"""
        # BucketService í˜¸ì¶œ
        pass
```

---

## 4. ì‹¤ì „ ì‹œë‚˜ë¦¬ì˜¤

### 4.1 ì‹œë‚˜ë¦¬ì˜¤ 1: ì—¬ëŸ¬ IDEA ë™ì‹œ ìƒì„±

**ìƒí™©**: ì‚¬ìš©ìê°€ 3ê°œ IDEAë¥¼ ë¹ ë¥´ê²Œ ì…ë ¥

```python
# Slackì—ì„œ ë¹ ë¥´ê²Œ 3ê°œ ë©”ì‹œì§€
#yoman-ideas: "AI ì—ì´ì „íŠ¸ ë§Œë“¤ê¸°"
#yoman-ideas: "ë¸”ë¡ì²´ì¸ í†µí•©"
#yoman-ideas: "ëª¨ë°”ì¼ ì•± ê°œë°œ"
```

**ì‹¤í–‰ íë¦„**:

```python
async def handle_concurrent_ideas():
    executor = CALMExecutor(db)

    # 3ê°œ IDEA ë™ì‹œ ìƒì„± ìš”ì²­
    operations = [
        {"type": "create", "bucket": "IDEA", "data": {"title": "AI ì—ì´ì „íŠ¸"}},
        {"type": "create", "bucket": "IDEA", "data": {"title": "ë¸”ë¡ì²´ì¸ í†µí•©"}},
        {"type": "create", "bucket": "IDEA", "data": {"title": "ëª¨ë°”ì¼ ì•±"}},
    ]

    # CALM executorê°€ íŒë‹¨: ëª¨ë‘ monotonic â†’ ë³‘ë ¬ ì‹¤í–‰
    results = await executor.execute_batch(operations)

    # 3ê°œ IDEAì˜ vector clockì€ CONCURRENT
    idea1_clock = VectorClock.from_json(results[0]["vector_clock"])
    idea2_clock = VectorClock.from_json(results[1]["vector_clock"])
    idea3_clock = VectorClock.from_json(results[2]["vector_clock"])

    assert idea1_clock.compare(idea2_clock) == 'CONCURRENT'
    assert idea2_clock.compare(idea3_clock) == 'CONCURRENT'
    assert idea1_clock.compare(idea3_clock) == 'CONCURRENT'

    # Slack ì•Œë¦¼
    await slack_notify(
        channel="yoman-ideas",
        message="ğŸ’¡ 3ê°œì˜ IDEAê°€ ë™ì‹œì— ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤ (ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ)"
    )
```

### 4.2 ì‹œë‚˜ë¦¬ì˜¤ 2: GAN ê²€ì¦ ì‹¤íŒ¨ í›„ ì¬ì‘ì—…

**ìƒí™©**: PRì´ REVIEWERì— ì˜í•´ ê±°ë¶€ë¨ â†’ TODO ìˆ˜ì • í•„ìš”

```python
async def handle_review_failure():
    # 1. PR ë¦¬ë·°
    reviewer = Reviewer()
    result = await reviewer.review_pr(pr_id="pr-123", db=db)

    if result["verdict"] == "FAIL":
        # 2. TODO ìˆ˜ì • (ìƒˆ ë²„ì „ ìƒì„±)
        todo_id = "todo-45"
        old_todo = db.table("todos").select("*").eq("id", todo_id).execute().data[0]

        # 3. í”¼ë“œë°± ë°˜ì˜ (ìƒˆ ë²„ì „)
        updated_content = {
            **old_todo["content"],
            "feedback": result["details"],
            "revised": True
        }

        # Vector clock ì¦ê°€
        new_clock = VectorClock.from_json(old_todo["vector_clock"])
        new_clock.increment("yoman_server")

        # 4. ìƒˆ ë²„ì „ ìƒì„± (append-only, monotonic)
        new_version = old_todo["version"] + 1
        db.table("todos").insert({
            "id": todo_id,
            "version": new_version,
            "content": updated_content,
            "vector_clock": new_clock.to_json(),
            "dependencies": old_todo["dependencies"] + [
                {"id": "pr-123", "bucket": "PR", "version": 1}  # ì‹¤íŒ¨í•œ PRì— ì˜ì¡´
            ]
        }).execute()

        # 5. CODINGBOT ì¬ì‹¤í–‰
        codingbot = CodingBot()
        new_pr_id = await codingbot.generate_code(todo_id, db)

        # 6. Slack ì•Œë¦¼
        await slack_notify(
            channel="yoman-todos",
            message=f"ğŸ”„ TODO {todo_id} v{new_version} ìƒì„±ë¨\n"
                    f"ì´ì „ PR ì‹¤íŒ¨ í”¼ë“œë°± ë°˜ì˜\n"
                    f"ìƒˆ PR: {new_pr_id}"
        )
```

### 4.3 ì‹œë‚˜ë¦¬ì˜¤ 3: Prerequisites ì²´ì¸

**ìƒí™©**: TODO-3ì´ TODO-1, TODO-2ì— ì˜ì¡´ (ìˆœì°¨ ì‹¤í–‰ í•„ìš”)

```python
async def handle_prerequisite_chain():
    """
    Prerequisites ì²´ì¸:
    TODO-1 â†’ TODO-2 â†’ TODO-3
    """

    # 1. TODO-1 ìƒì„± (ì˜ì¡´ì„± ì—†ìŒ)
    todo1_id = await bucket_service.create_todo(
        research_id="research-10",
        content={"title": "DB ìŠ¤í‚¤ë§ˆ ì„¤ê³„"},
        prerequisites=[],
        user_id="user1"
    )

    # 2. TODO-2 ìƒì„± (TODO-1ì— ì˜ì¡´)
    todo2_id = await bucket_service.create_todo(
        research_id="research-10",
        content={"title": "API ì—”ë“œí¬ì¸íŠ¸ êµ¬í˜„"},
        prerequisites=[todo1_id],  # TODO-1 ì™„ë£Œ í•„ìš”
        user_id="user1"
    )

    # 3. TODO-3 ìƒì„± (TODO-1, TODO-2ì— ì˜ì¡´)
    todo3_id = await bucket_service.create_todo(
        research_id="research-10",
        content={"title": "í”„ë¡ íŠ¸ì—”ë“œ ì—°ë™"},
        prerequisites=[todo1_id, todo2_id],
        user_id="user1"
    )

    # 4. Vector clock ê´€ê³„ í™•ì¸
    todo1 = await get_operation(todo1_id)
    todo2 = await get_operation(todo2_id)
    todo3 = await get_operation(todo3_id)

    assert todo1.vector_clock.compare(todo2.vector_clock) == 'BEFORE'
    assert todo2.vector_clock.compare(todo3.vector_clock) == 'BEFORE'
    assert todo1.vector_clock.compare(todo3.vector_clock) == 'BEFORE'

    # 5. ì˜ì¡´ì„± ê·¸ë˜í”„ ì‹œê°í™”
    graph = CausalGraphVisualizer.render_dependency_graph(todo3_id, db)

    await slack_notify(
        channel="yoman-todos",
        message=f"ğŸ“Š TODO ì²´ì¸ ìƒì„± ì™„ë£Œ\n\n{graph}"
    )
```

---

## 5. ëª¨ë‹ˆí„°ë§ ë° ë””ë²„ê¹…

### 5.1 Causal Anomaly ê°ì§€

```python
# yoman/monitoring/causal_checker.py

class CausalAnomalyDetector:
    """
    Causal consistency ìœ„ë°˜ ê°ì§€

    - ìˆœí™˜ ì˜ì¡´ì„± (circular dependency)
    - ì˜ì¡´ì„± ëˆ„ë½ (missing dependency)
    - ìˆœì„œ ìœ„ë°˜ (order violation)
    """

    def __init__(self, db: Client):
        self.db = db

    async def detect_circular_dependency(self, op_id: str) -> Optional[list]:
        """
        ìˆœí™˜ ì˜ì¡´ì„± ê°ì§€

        Returns:
            ìˆœí™˜ ê²½ë¡œ (ì—†ìœ¼ë©´ None)
        """

        visited = set()
        path = []

        def dfs(current_id: str) -> Optional[list]:
            if current_id in path:
                # ìˆœí™˜ ë°œê²¬
                cycle_start = path.index(current_id)
                return path[cycle_start:] + [current_id]

            if current_id in visited:
                return None

            visited.add(current_id)
            path.append(current_id)

            # ì˜ì¡´ì„± ì¡°íšŒ
            op = self.db.table("operations").select("dependencies").eq("id", current_id).execute()
            if not op.data:
                path.pop()
                return None

            deps = op.data[0].get("dependencies", [])

            for dep in deps:
                cycle = dfs(dep["id"])
                if cycle:
                    return cycle

            path.pop()
            return None

        cycle = dfs(op_id)

        if cycle:
            # Slack ì•Œë¦¼
            await slack_alert(
                channel="yoman-alerts",
                message=f"âš ï¸ *Circular Dependency Detected*\n\n"
                        f"Cycle: {' â†’ '.join(cycle)}"
            )

        return cycle

    async def check_consistency(self, op_id: str) -> dict:
        """
        ì „ì²´ consistency ì²´í¬

        Returns:
            ì²´í¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """

        op = await get_operation(op_id)

        issues = []

        # 1. ì˜ì¡´ì„± ì¡´ì¬ í™•ì¸
        for dep in op.dependencies:
            dep_op = await get_operation(dep.op_id)
            if not dep_op:
                issues.append({
                    "type": "missing_dependency",
                    "dep_id": dep.op_id
                })

        # 2. Vector clock ìˆœì„œ í™•ì¸
        for dep in op.dependencies:
            dep_op = await get_operation(dep.op_id)
            if dep_op:
                relation = dep_op.vector_clock.compare(op.vector_clock)
                if relation != 'BEFORE':
                    issues.append({
                        "type": "order_violation",
                        "dep_id": dep.op_id,
                        "expected": "BEFORE",
                        "actual": relation
                    })

        # 3. ìˆœí™˜ ì˜ì¡´ì„± í™•ì¸
        cycle = await self.detect_circular_dependency(op_id)
        if cycle:
            issues.append({
                "type": "circular_dependency",
                "cycle": cycle
            })

        return {
            "op_id": op_id,
            "consistent": len(issues) == 0,
            "issues": issues
        }
```

### 5.2 Slack Dashboard

```python
# yoman/slack/dashboard.py

class CausalDashboard:
    """Slackì— causal consistency í˜„í™© ëŒ€ì‹œë³´ë“œ"""

    @staticmethod
    async def render_daily_report(slack_client: any):
        """
        ì¼ì¼ ë¦¬í¬íŠ¸

        - ì´ operations
        - Concurrent operations ë¹„ìœ¨
        - Causal chain ê¸¸ì´ í‰ê· 
        - ì´ìƒ íƒì§€ ê²°ê³¼
        """

        stats = await compute_stats()

        message = f"""
ğŸ“Š *YOMAN Causal Consistency Report* - {datetime.now().strftime('%Y-%m-%d')}

*Operations*
â€¢ Total: {stats['total_ops']}
â€¢ IDEA: {stats['idea_count']}
â€¢ RESEARCH: {stats['research_count']}
â€¢ TODO: {stats['todo_count']}
â€¢ PR: {stats['pr_count']}

*Concurrency*
â€¢ Concurrent ops: {stats['concurrent_ops']} ({stats['concurrent_ratio']:.1%})
â€¢ Parallel executions: {stats['parallel_count']}

*Causal Chains*
â€¢ Avg chain length: {stats['avg_chain_length']:.1f}
â€¢ Max chain length: {stats['max_chain_length']}

*Anomalies*
â€¢ Circular dependencies: {stats['circular_deps']}
â€¢ Missing dependencies: {stats['missing_deps']}
â€¢ Order violations: {stats['order_violations']}

{'âœ… All clear!' if stats['anomaly_count'] == 0 else 'âš ï¸ Issues detected'}
        """

        await slack_client.chat_postMessage(
            channel="yoman-alerts",
            text=message
        )
```

---

## 6. ì„±ëŠ¥ ìµœì í™”

### 6.1 Vector Clock ì••ì¶•

```python
# yoman/optimization/vc_compression.py

class VectorClockOptimizer:
    """
    Vector clock ìµœì í™”

    - 0ì¸ ì—”íŠ¸ë¦¬ ì œê±°
    - ë¹„í™œì„± ë…¸ë“œ prune
    - Delta encoding
    """

    @staticmethod
    def compress(vc: VectorClock) -> dict:
        """0ì¸ ì—”íŠ¸ë¦¬ ì œê±° í›„ JSON ë³€í™˜"""
        compressed = {k: v for k, v in vc.clocks.items() if v > 0}
        return compressed

    @staticmethod
    async def prune_inactive_nodes(
        vc: VectorClock,
        db: Client,
        inactive_days: int = 30
    ) -> VectorClock:
        """
        ë¹„í™œì„± ë…¸ë“œ ì œê±°

        Args:
            vc: Vector clock
            db: Database client
            inactive_days: ë©°ì¹  ë™ì•ˆ í™œë™ ì—†ìœ¼ë©´ ì œê±°

        Returns:
            Pruned vector clock
        """

        # ìµœê·¼ active nodes ì¡°íšŒ
        cutoff = datetime.now() - timedelta(days=inactive_days)

        active_nodes = db.table("operations")\
            .select("node_id")\
            .gte("updated_at", cutoff.isoformat())\
            .execute()

        active_set = {row["node_id"] for row in active_nodes.data}

        # Prune
        pruned_clocks = {
            k: v for k, v in vc.clocks.items()
            if k in active_set
        }

        return VectorClock(clocks=pruned_clocks)
```

### 6.2 Dependency Cache

```python
# yoman/optimization/dep_cache.py

from functools import lru_cache

class DependencyCache:
    """
    ì˜ì¡´ì„± ì¡°íšŒ ìºì‹±

    ìì£¼ ì¡°íšŒë˜ëŠ” operationsëŠ” ë©”ëª¨ë¦¬ì— ìºì‹œ
    """

    def __init__(self, max_size: int = 1000):
        self.cache = {}
        self.max_size = max_size
        self.hits = 0
        self.misses = 0

    def get(self, op_id: str) -> Optional[Operation]:
        """ìºì‹œ ì¡°íšŒ"""
        if op_id in self.cache:
            self.hits += 1
            return self.cache[op_id]

        self.misses += 1
        return None

    def put(self, op: Operation) -> None:
        """ìºì‹œ ì €ì¥"""
        if len(self.cache) >= self.max_size:
            # LRU eviction
            oldest = min(self.cache.values(), key=lambda o: o.updated_at)
            del self.cache[oldest.id]

        self.cache[op.id] = op

    def hit_rate(self) -> float:
        """ìºì‹œ hit rate"""
        total = self.hits + self.misses
        return self.hits / total if total > 0 else 0.0
```

---

## 7. ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš

### 7.1 Phase 1: ê¸°ë³¸ ì¸í”„ë¼ (2ì£¼)

**Week 1**:
- [ ] Supabase schema í™•ì¥ (vector_clock, dependencies ì»¬ëŸ¼)
- [ ] Python VectorClock, Operation í´ë˜ìŠ¤ êµ¬í˜„
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±

**Week 2**:
- [ ] BucketServiceì— causal consistency ì ìš©
- [ ] Slack ì•Œë¦¼ì— dependency ì •ë³´ ì¶”ê°€
- [ ] í†µí•© í…ŒìŠ¤íŠ¸

### 7.2 Phase 2: GAN ê²€ì¦ (2ì£¼)

**Week 3**:
- [ ] CodingBotì— vector clock ì ìš©
- [ ] Reviewerì— dual dependency ì¶”ê°€ (PR + TODO)
- [ ] PR ì‹¤íŒ¨ ì‹œ ì¬ì‘ì—… íë¦„ êµ¬í˜„

**Week 4**:
- [ ] ì–‘ì ê²€ì¦ (concurrent unit generation)
- [ ] CALM executor êµ¬í˜„
- [ ] ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

### 7.3 Phase 3: ëª¨ë‹ˆí„°ë§ ë° ìµœì í™” (1-2ì£¼)

**Week 5-6**:
- [ ] Causal anomaly ê°ì§€
- [ ] Slack dashboard
- [ ] Vector clock ì••ì¶•
- [ ] Dependency cache
- [ ] ì „ì²´ ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸

---

## 8. ì˜ˆìƒ íš¨ê³¼

### 8.1 ì •ëŸ‰ì  ì§€í‘œ

| ë©”íŠ¸ë¦­ | Before | After (ì˜ˆìƒ) | ê°œì„ ìœ¨ |
|--------|--------|------------|--------|
| **ë³‘ë ¬ ì²˜ë¦¬ ì•ˆì •ì„±** | 60% (race condition) | 95% (causal ordering) | **+58%** |
| **ì˜ì¡´ì„± ì¶”ì ** | ìˆ˜ë™ (ë¬¸ì„œ) | ìë™ (vector clock) | **100% ìë™í™”** |
| **ë””ë²„ê¹… ì‹œê°„** | 2ì‹œê°„ (ì˜ì¡´ì„± ì—­ì¶”ì ) | 10ë¶„ (ê·¸ë˜í”„ ì¡°íšŒ) | **91% ë‹¨ì¶•** |
| **Concurrent ops** | 1-2ê°œ | 5-10ê°œ (CALM) | **5ë°° ì¦ê°€** |

### 8.2 ì •ì„±ì  íš¨ê³¼

**ì‹ ë¢°ë„**:
- Prerequisites ìë™ ê²€ì¦
- ìˆœí™˜ ì˜ì¡´ì„± ì‚¬ì „ ì°¨ë‹¨
- GAN ê²€ì¦ ì •í™•ë„ í–¥ìƒ

**ê°€ì‹œì„±**:
- ì „ì²´ ì˜ì¡´ì„± ê·¸ë˜í”„ ì‹¤ì‹œê°„ í™•ì¸
- Causal chain ì‹œê°í™”
- Slack dashboardë¡œ í˜„í™© íŒŒì•…

**í™•ì¥ì„±**:
- CALM theoremìœ¼ë¡œ coordination-free í™•ì¥
- ì—¬ëŸ¬ AI ëª¨ë¸ ë³‘ë ¬ ì‹¤í–‰
- ë¶„ì‚° ë…¸ë“œ ì¶”ê°€ ìš©ì´

---

## 9. ê²°ë¡ 

### 9.1 í•µì‹¬ ìš”ì•½

1. **YOMANì€ causal systemì„**
   - REVIEWERê°€ ìˆì–´ë„ causal chain ìœ ì§€
   - GAN ê²€ì¦ íŒ¨í„´ë„ causal

2. **Causal consistency ì ìš© ê°€ëŠ¥**
   - Vector clockìœ¼ë¡œ ì¸ê³¼ê´€ê³„ ì¶”ì 
   - COPS-style dependency tracking
   - CALM theoremìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬ ìµœì í™”

3. **ì‹ ë¢°ë„ì™€ ì„±ëŠ¥ ë™ì‹œ í–¥ìƒ**
   - Prerequisites ìë™ ê²€ì¦
   - Concurrent operations ë³‘ë ¬ ì²˜ë¦¬
   - Anomaly ì‚¬ì „ ê°ì§€

### 9.2 ë‹¤ìŒ ë‹¨ê³„

1. **í”„ë¡œí† íƒ€ì… êµ¬í˜„** (Phase 1) - 2ì£¼
2. **GAN ê²€ì¦ í†µí•©** (Phase 2) - 2ì£¼
3. **í”„ë¡œë•ì…˜ ë°°í¬** (Phase 3) - 1-2ì£¼
4. **ë…¼ë¬¸ ì‘ì„±** - YOMANì˜ causal consistency ì‚¬ë¡€ ì—°êµ¬

---

**ë¬¸ì„œ ì‘ì„±**: 2026-01-01
**ì‘ì„±ì**: Claude Sonnet 4.5
**ê´€ë ¨ ë¬¸ì„œ**: [00-causal-consistency-overview.md](./00-causal-consistency-overview.md), [01-algorithms-implementation.md](./01-algorithms-implementation.md)
